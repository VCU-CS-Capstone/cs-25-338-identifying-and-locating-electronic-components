{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn #related to neural networks\n",
    "import torch.optim as optim #optimizer\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision\n",
    "import os\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "from torchvision import transforms, models\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import numpy as np\n",
    "import sys\n",
    "import timm\n",
    "import tqdm\n",
    "from PIL import Image\n",
    "import json\n",
    "from pycocotools.coco import COCO\n",
    "\n",
    "import matplotlib.patches as patches\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "def get_labels(yaml_file_path):\n",
    "    with open(yaml_file_path, \"r\") as file:\n",
    "        yaml_content = yaml.safe_load(file)\n",
    "    return yaml_content.get(\"names\", [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Number of images: 160\n",
      "Number of annotations: 201\n",
      "Number of categories: 40\n",
      "Image: {'file_name': 'Screenshot 2024-10-11 174314.png', 'height': 804, 'width': 811, 'id': 150}\n",
      "[{'id': 191, 'image_id': 150, 'category_id': 38, 'area': 112050.0, 'iscrowd': 0, 'segmentation': [[92, 305, 507, 305, 507, 575, 92, 575]], 'bbox': [92, 305, 415, 270]}]\n",
      "[[92, 305, 415, 270]]\n",
      "Label: WAVETRAP_NOPOT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@0.074] global loadsave.cpp:268 findDecoder imread_('images/Screenshot 2024-10-11 174314.png'): can't open/read file: check file path/integrity\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.11.0) /Users/xperience/GHA-Actions-OpenCV/_work/opencv-python/opencv-python/opencv/modules/imgproc/src/color.cpp:199: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 23\u001b[0m\n\u001b[1;32m     21\u001b[0m image_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimages/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m image[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfile_name\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     22\u001b[0m image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(image_path)\n\u001b[0;32m---> 23\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcvtColor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCOLOR_BGR2RGB\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Plot the image\u001b[39;00m\n\u001b[1;32m     26\u001b[0m fig, ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m1\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m8\u001b[39m))\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.11.0) /Users/xperience/GHA-Actions-OpenCV/_work/opencv-python/opencv-python/opencv/modules/imgproc/src/color.cpp:199: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
     ]
    }
   ],
   "source": [
    "with open(\"annotations.json\", \"r\") as file:\n",
    "    coco_data = json.load(file)\n",
    "coco = COCO(\"annotations.json\")\n",
    "print(f\"Number of images: {len(coco_data['images'])}\")\n",
    "print(f\"Number of annotations: {len(coco_data['annotations'])}\")\n",
    "print(f\"Number of categories: {len(coco_data['categories'])}\")\n",
    "\n",
    "x = 150\n",
    "# Load a specific image by ID\n",
    "image = coco.loadImgs(x)[0]\n",
    "print(f\"Image: {image}\")\n",
    "\n",
    "annotations = coco.loadAnns(coco.getAnnIds(imgIds=x))\n",
    "print(annotations)\n",
    "bounding_boxes = [ann['bbox'] for ann in annotations]\n",
    "print(bounding_boxes)\n",
    "label = coco.loadCats([annotations[0]['category_id']][0])[0]['name']\n",
    "print(f\"Label: {label}\")\n",
    "\n",
    "# Load the image\n",
    "image_path = \"images/\" + image['file_name']\n",
    "image = cv2.imread(image_path)\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Plot the image\n",
    "fig, ax = plt.subplots(1, figsize=(12, 8))\n",
    "ax.imshow(image)\n",
    "\n",
    "# Add bounding boxes\n",
    "for ann in annotations:\n",
    "    bbox = ann['bbox']  # [x, y, width, height]\n",
    "    rect = patches.Rectangle(\n",
    "        (bbox[0], bbox[1]),\n",
    "        bbox[2],\n",
    "        bbox[3],\n",
    "        linewidth=2,\n",
    "        edgecolor='red',\n",
    "        facecolor='none'\n",
    "    )\n",
    "    ax.add_patch(rect)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Circuit Diagram Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CircuitDiagramDataset(Dataset):\n",
    "    def __init__(self, image_path, transform=None):\n",
    "        self.ann_dir = os.path.join('annotations.json')\n",
    "        self.image_dir = image_path\n",
    "        self.transform = transform        \n",
    "        self.coco = COCO(\"annotations.json\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.coco.getImgIds())\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.image_dir, self.coco.loadImgs(idx)[0]['file_name'])\n",
    "        \n",
    "        # Load the image using PIL\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        image_id = self.coco.loadImgs(idx)[0]['id']\n",
    "        \n",
    "        # Get annotation IDs for the image\n",
    "        ann_ids = self.coco.getAnnIds(imgIds=idx)\n",
    "        annotations = self.coco.loadAnns(ann_ids)\n",
    "        \n",
    "        # Prepare the annotations (usually bounding boxes and category labels)\n",
    "        boxes = []\n",
    "        labels = []\n",
    "        for ann in annotations:\n",
    "            bbox = ann['bbox']  # [x, y, width, height]\n",
    "            bbox[2] += bbox[0]  # x + width\n",
    "            bbox[3] += bbox[1]  # y + height\n",
    "            category_id = ann['category_id']\n",
    "            boxes.append(bbox)\n",
    "            labels.append(category_id)\n",
    "        \n",
    "        # Convert boxes and labels to tensors\n",
    "        boxes = torch.tensor(boxes, dtype=torch.float32)\n",
    "        labels = torch.tensor(labels, dtype=torch.int64)\n",
    "        \n",
    "        # Apply the transformations (if any)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        original_width, original_height = self.coco.loadImgs(idx)[0]['width'], self.coco.loadImgs(idx)[0]['height']\n",
    "        scale_x = 224 / original_width\n",
    "        scale_y = 224 / original_height\n",
    "        for i in range(len(boxes)):\n",
    "            boxes[i][0] *= scale_x  # x\n",
    "            boxes[i][1] *= scale_y  # y\n",
    "            boxes[i][2] *= scale_x  # width\n",
    "            boxes[i][3] *= scale_y  # height\n",
    "        \n",
    "        # Create a target dictionary\n",
    "        target = {\n",
    "            \"boxes\": boxes,\n",
    "            \"labels\": labels,\n",
    "            \"image_id\": torch.tensor([image_id])\n",
    "        }\n",
    "        \n",
    "        # Return the image along with the bounding boxes and labels\n",
    "        return image, target\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image_with_boxes(image, boxes):\n",
    "    # Convert image tensor to a numpy array (from [C, H, W] to [H, W, C] and denormalize if necessary)\n",
    "    image = image.permute(1, 2, 0).numpy()\n",
    "    image = (image * 255).astype(\"uint8\")  # Denormalize if the image was normalized earlier\n",
    "    \n",
    "    # Create a figure and axis\n",
    "    fig, ax = plt.subplots(1, figsize=(10, 8))\n",
    "    \n",
    "    # Display the image\n",
    "    ax.imshow(image)\n",
    "    \n",
    "    # Add bounding boxes\n",
    "    for box in boxes:\n",
    "        xmin, ymin, xmax, ymax = map(int, box)\n",
    "        rect = patches.Rectangle(\n",
    "            (xmin, ymin),  # Starting point (x, y)\n",
    "            xmax - xmin,   # Width\n",
    "            ymax - ymin,   # Height\n",
    "            linewidth=2,\n",
    "            edgecolor='r',\n",
    "            facecolor='none'\n",
    "        )\n",
    "        ax.add_patch(rect)\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Image directory: 160\n",
      "Image shape: torch.Size([3, 224, 224])\n",
      "Boxes: tensor([[104.1983,  84.8900, 119.2727,  99.1296]])\n",
      "Labels: CAP\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "test = CircuitDiagramDataset(    \n",
    "    image_path=\"images\",\n",
    "    transform=transform)\n",
    "\n",
    "image, target = test[41]\n",
    "boxes = target[\"boxes\"]\n",
    "labels = target[\"labels\"]\n",
    "print(f\"Image directory: {len(test.coco.getImgIds())}\")\n",
    "print(f\"Image shape: {image.shape}\")\n",
    "print(f\"Boxes: {boxes}\")    \n",
    "print(f\"Labels: {test.coco.loadCats(labels.numpy())[0]['name']}\")\n",
    "plot_image_with_boxes(image, boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train = CircuitDiagramDataset(    \n",
    "    image_path=\"images\",\n",
    "    transform=transform)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    images, targets = zip(*batch)\n",
    "    return list(images), list(targets)\n",
    "\n",
    "train_dataloader = DataLoader(train, batch_size=4, shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "\n",
    "def get_model(num_classes=40):\n",
    "    # Where we define all the parts of the model\n",
    "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(weights='DEFAULT')\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import v2 as T\n",
    "\n",
    "def get_transform(train):\n",
    "    transforms = []\n",
    "    if train:\n",
    "        transforms.append(T.RandomHorizontalFlip(0.5))\n",
    "    transforms.append(T.ToDtype(torch.float, scale=True))\n",
    "    transforms.append(T.ToPureTensor())\n",
    "    return T.Compose(transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mget_model\u001b[49m(num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m41\u001b[39m)\n\u001b[1;32m      2\u001b[0m model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mtrain_one_epoch\u001b[39m(model, optimizer, data_loader, device, epoch):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_model' is not defined"
     ]
    }
   ],
   "source": [
    "model = get_model(num_classes=41)\n",
    "model.to(device)\n",
    "def train_one_epoch(model, optimizer, data_loader, device, epoch):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for images, targets in tqdm.tqdm(data_loader, desc=f\"Epoch {epoch}\"):\n",
    "        # Ensure valid images and targets\n",
    "        valid_samples = []\n",
    "        for image, target in zip(images, targets):\n",
    "            if target[\"image_id\"].item() == 0:  # Skip image_id=0\n",
    "                continue\n",
    "            valid_samples.append((image, target))\n",
    "\n",
    "        # Skip if no valid samples\n",
    "        if not valid_samples:\n",
    "            continue\n",
    "\n",
    "        # Separate valid images and targets\n",
    "        images = [sample[0].to(device) for sample in valid_samples]\n",
    "        targets = [{k: v.to(device) for k, v in sample[1].items()} for sample in valid_samples]\n",
    "\n",
    "        try:\n",
    "            # Forward pass\n",
    "            loss_dict = model(images, targets)\n",
    "            losses = sum(loss for loss in loss_dict.values())\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            losses.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += losses.item()\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error in processing batch: {e}\")\n",
    "            continue\n",
    "\n",
    "    avg_loss = total_loss / len(data_loader)\n",
    "    print(f\"Epoch {epoch} - Average Loss: {avg_loss:.4f}\")\n",
    "\n",
    "# Define optimizer and learning rate scheduler\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
    "lr_scheduler = StepLR(optimizer, step_size=3, gamma=0.1)\n",
    "\n",
    "# Train the model for a few epochs\n",
    "num_epochs = 1\n",
    "for epoch in range(num_epochs):\n",
    "    train_one_epoch(model, optimizer, train_dataloader, device, epoch)\n",
    "    lr_scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.69 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.23 ðŸš€ Python-3.12.6 torch-2.5.1 MPS (Apple M2)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolo11n.pt, data=./data.yaml, epochs=40, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=mps, workers=8, project=None, name=train13, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/Users/enerinn/Developer/CS25-338-main/runs/detect/train13\n",
      "Overriding model.yaml nc=80 with nc=40\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
      " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
      " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
      " 23        [16, 19, 22]  1    438472  ultralytics.nn.modules.head.Detect           [40, [64, 128, 256]]          \n",
      "YOLO11n summary: 319 layers, 2,597,640 parameters, 2,597,624 gradients, 6.5 GFLOPs\n",
      "\n",
      "Transferred 448/499 items from pretrained weights\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/enerinn/Developer/CS25-338-main/Model/labels/train.cache... 160 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 160/160 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/enerinn/Developer/CS25-338-main/Model/labels/val.cache... 40 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to /Users/enerinn/Developer/CS25-338-main/runs/detect/train13/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000227, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1m/Users/enerinn/Developer/CS25-338-main/runs/detect/train13\u001b[0m\n",
      "Starting training for 40 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/40      4.59G      2.495      6.299      1.735         27        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:14<00:00,  1.45s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00:00,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         40         56          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/40      4.58G      2.089       5.96      1.572         35        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:12<00:00,  1.25s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         40         56          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/40      4.57G      1.823      5.588      1.458         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:12<00:00,  1.23s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         40         56          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/40       4.6G      1.665      5.449      1.345         28        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:12<00:00,  1.25s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         40         56          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/40      4.62G      1.487      5.092      1.195         38        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:12<00:00,  1.21s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         40         56          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/40      4.61G      1.471      4.921      1.182         53        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:11<00:00,  1.14s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         40         56          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/40      4.64G      1.364      4.809       1.15         35        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:11<00:00,  1.13s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:06<00:00,  3.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         40         56       0.01      0.113     0.0305     0.0228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/40      4.65G      1.345      4.545      1.161         24        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:12<00:00,  1.26s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:06<00:00,  3.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         40         56     0.0255      0.283     0.0576     0.0385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/40      4.66G       1.34      4.543      1.145         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:13<00:00,  1.34s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:08<00:00,  4.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         40         56     0.0151      0.308      0.105     0.0736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/40      4.66G      1.297      4.477      1.165         26        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:12<00:00,  1.26s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:06<00:00,  3.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         40         56     0.0428       0.56       0.22      0.152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/40      4.69G      1.432      4.406        1.2         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:12<00:00,  1.23s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:08<00:00,  4.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         40         56     0.0347      0.619       0.24       0.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/40      4.71G      1.299       4.15      1.157         39        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:14<00:00,  1.50s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:10<00:00,  5.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         40         56      0.908     0.0964      0.241      0.179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/40      4.72G      1.294      4.116       1.12         35        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:13<00:00,  1.39s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING âš ï¸ NMS time limit 3.600s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:10<00:00,  5.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         40         56      0.767      0.108      0.233      0.176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/40      4.75G      1.279      4.069      1.139         32        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:14<00:00,  1.47s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING âš ï¸ NMS time limit 3.600s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         40         56      0.625       0.17      0.282      0.227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/40      4.74G      1.275      3.879       1.12         38        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:27<00:00,  2.76s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         40         56      0.737      0.174      0.329      0.244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/40      4.77G      1.178      3.868      1.115         28        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:13<00:00,  1.37s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING âš ï¸ NMS time limit 3.600s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:08<00:00,  4.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         40         56      0.732      0.245      0.316      0.234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/40      4.79G      1.219      3.988      1.136         29        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:14<00:00,  1.46s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING âš ï¸ NMS time limit 3.600s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:10<00:00,  5.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         40         56      0.765      0.302      0.378       0.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/40       4.8G      1.272      3.809      1.125         29        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:17<00:00,  1.78s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING âš ï¸ NMS time limit 3.600s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:13<00:00,  6.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         40         56      0.702      0.321      0.383      0.271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/40      4.84G       1.19      3.699      1.132         32        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:14<00:00,  1.46s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING âš ï¸ NMS time limit 3.600s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:10<00:00,  5.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         40         56      0.704      0.324      0.361      0.258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/40      4.85G       1.26      3.741      1.166         27        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:18<00:00,  1.82s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING âš ï¸ NMS time limit 3.600s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:10<00:00,  5.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         40         56        0.6      0.336      0.348      0.258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      21/40      4.86G      1.216      3.526      1.118         45        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:16<00:00,  1.65s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:09<00:00,  4.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         40         56      0.558      0.372      0.363      0.256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      22/40      4.89G      1.228      3.502      1.137         25        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:15<00:00,  1.53s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING âš ï¸ NMS time limit 3.600s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         40         56      0.629      0.276      0.349      0.251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      23/40       4.9G      1.156      3.562      1.085         27        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:17<00:00,  1.75s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING âš ï¸ NMS time limit 3.600s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:15<00:00,  7.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         40         56      0.597      0.339      0.389      0.278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      24/40      4.89G      1.163      3.505      1.095         19        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:20<00:00,  2.05s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING âš ï¸ NMS time limit 3.600s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         40         56      0.693       0.33      0.365       0.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      25/40      4.91G       1.17      3.297      1.105         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:16<00:00,  1.64s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING âš ï¸ NMS time limit 3.600s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:10<00:00,  5.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         40         56      0.682      0.367      0.414      0.323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      26/40      4.92G      1.176      3.509      1.129         23        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:19<00:00,  1.92s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING âš ï¸ NMS time limit 3.600s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         40         56      0.701      0.381      0.438      0.346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      27/40      4.95G      1.174      3.194      1.124         45        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:18<00:00,  1.86s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING âš ï¸ NMS time limit 3.600s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:09<00:00,  4.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         40         56       0.67      0.402      0.428      0.331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      28/40      4.94G      1.121      3.242      1.113         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:17<00:00,  1.79s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING âš ï¸ NMS time limit 3.600s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:10<00:00,  5.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         40         56       0.59      0.421      0.493      0.375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      29/40      4.95G      1.205      3.532      1.131         27        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:17<00:00,  1.78s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING âš ï¸ NMS time limit 3.600s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:09<00:00,  4.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         40         56      0.668      0.362      0.457      0.365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      30/40      4.96G      1.108      3.147      1.103         36        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:17<00:00,  1.77s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING âš ï¸ NMS time limit 3.600s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         40         56      0.782      0.381      0.483      0.386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      31/40      4.98G      1.057       3.52      1.103         22        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:23<00:00,  2.30s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING âš ï¸ NMS time limit 3.600s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:10<00:00,  5.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         40         56      0.802      0.411      0.495      0.393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      32/40         5G      1.047      3.446      1.034         23        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:15<00:00,  1.58s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING âš ï¸ NMS time limit 3.600s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         40         56      0.809      0.294      0.362      0.279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      33/40      5.03G      1.046       3.58      1.057         18        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:19<00:00,  1.97s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING âš ï¸ NMS time limit 3.600s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:09<00:00,  4.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         40         56      0.784      0.403      0.468      0.363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      34/40      5.06G      1.007      3.412      1.019         18        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:17<00:00,  1.71s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING âš ï¸ NMS time limit 3.600s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         40         56      0.842      0.398      0.467      0.361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      35/40       5.1G      1.013      3.351      1.061         18        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:16<00:00,  1.68s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING âš ï¸ NMS time limit 3.600s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:09<00:00,  4.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         40         56       0.83      0.407      0.455      0.355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      36/40      5.12G     0.9987      3.179      1.046         20        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:15<00:00,  1.53s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING âš ï¸ NMS time limit 3.600s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         40         56      0.825      0.392      0.482      0.385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      37/40      5.12G      1.022      3.323       1.05         19        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:18<00:00,  1.82s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING âš ï¸ NMS time limit 3.600s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:10<00:00,  5.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         40         56      0.855      0.366      0.441      0.352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      38/40      5.13G     0.9773      3.288      1.063         16        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:17<00:00,  1.70s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING âš ï¸ NMS time limit 3.600s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         40         56      0.823      0.403      0.521      0.417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      39/40      5.14G      1.016      3.304      1.048         24        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:15<00:00,  1.53s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING âš ï¸ NMS time limit 3.600s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:11<00:00,  5.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         40         56      0.826      0.421      0.532      0.431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      40/40      5.17G     0.9873      3.355       1.03         16        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:34<00:00,  3.44s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING âš ï¸ NMS time limit 3.600s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:08<00:00,  4.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         40         56      0.837      0.408      0.485       0.39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "40 epochs completed in 0.297 hours.\n",
      "Optimizer stripped from /Users/enerinn/Developer/CS25-338-main/runs/detect/train13/weights/last.pt, 5.5MB\n",
      "Optimizer stripped from /Users/enerinn/Developer/CS25-338-main/runs/detect/train13/weights/best.pt, 5.5MB\n",
      "\n",
      "Validating /Users/enerinn/Developer/CS25-338-main/runs/detect/train13/weights/best.pt...\n",
      "Ultralytics 8.3.23 ðŸš€ Python-3.12.6 torch-2.5.1 MPS (Apple M2)\n",
      "YOLO11n summary (fused): 238 layers, 2,589,952 parameters, 0 gradients, 6.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING âš ï¸ NMS time limit 3.600s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:19<00:00,  9.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         40         56      0.822       0.41      0.531      0.431\n",
      "                  25FP          1          2          1      0.756      0.995      0.722\n",
      "                  30FP          1          3      0.858          1      0.995      0.698\n",
      "                  35FP          1          3      0.811          1      0.995      0.781\n",
      "            38BRKR_ATT          1          2      0.715          1      0.995      0.895\n",
      "                  40FP          1          4      0.423       0.75      0.538      0.406\n",
      "                  45FP          1          3      0.804          1      0.995      0.886\n",
      "                50FPUP          1          1          1          0          0          0\n",
      "                 Arrow          1          1          1          0          0          0\n",
      "              AUTOXFMR          1          1          1          0          0          0\n",
      "              BRKR_ATT          1          1          1          0          0          0\n",
      "                   CAP          1          1          1          0      0.332      0.298\n",
      "                 CKTSW          1          1          1          0          0          0\n",
      "                    CT          1          1      0.573          1      0.995      0.597\n",
      "                CTASSY          1          1          1          0          0          0\n",
      "                   DDE          1          1      0.642          1      0.995      0.895\n",
      "               DIPPOLE          1          1      0.666          1      0.995      0.895\n",
      "                 FRGNP          1          4      0.842          1      0.995      0.865\n",
      "                FUCLSP          1          1          1          0     0.0622      0.056\n",
      "               FUCOMGO          1          1          1          0          0          0\n",
      "                   GEN          1          3      0.655      0.667      0.863      0.772\n",
      "                  GEN1          1          1      0.269      0.539      0.497      0.497\n",
      "                 GNDSW          1          1          1          0      0.249      0.224\n",
      "                  GOBS          1          1      0.572          1      0.995      0.796\n",
      "                JUMPER          1          1          1          0      0.332      0.232\n",
      "                   LDE          1          1      0.337      0.675      0.497      0.398\n",
      "               LTERMLB          1          1          1          0      0.497      0.448\n",
      "              LTERMNLB          1          1          1          0          0          0\n",
      "                  MOCS          1          1          1          0          0          0\n",
      "                PTXFMR          1          1          1          0     0.0765     0.0689\n",
      "                   REG          1          1          1          0      0.995      0.597\n",
      "                   SBD          1          1          1          0      0.332      0.199\n",
      "                   SEC          1          1          1          0     0.0415      0.029\n",
      "                   SPD          1          1          1          0          0          0\n",
      "              STA_SERV          1          1      0.739          1      0.995      0.995\n",
      "               SWFUCOM          1          1          1          0      0.995      0.796\n",
      "                  TPGO          1          1          1          0      0.995      0.895\n",
      "              WAVETRAP          1          1      0.679          1      0.995      0.697\n",
      "        WAVETRAP_NOPOT          1          1          0          0          0          0\n",
      "          WAVETRAP_POT          1          1      0.691          1      0.995      0.895\n",
      "                  XFMR          1          1      0.611          1      0.995      0.697\n",
      "Speed: 0.5ms preprocess, 99.2ms inference, 0.0ms loss, 119.9ms postprocess per image\n",
      "Results saved to \u001b[1m/Users/enerinn/Developer/CS25-338-main/runs/detect/train13\u001b[0m\n",
      "Ultralytics 8.3.23 ðŸš€ Python-3.12.6 torch-2.5.1 MPS (Apple M2)\n",
      "YOLO11n summary (fused): 238 layers, 2,589,952 parameters, 0 gradients, 6.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/enerinn/Developer/CS25-338-main/Model/labels/val.cache... 40 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING âš ï¸ NMS time limit 2.800s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:22<00:00,  7.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         40         56      0.749      0.498      0.651      0.523\n",
      "                  25FP          1          2          1      0.792      0.995      0.721\n",
      "                  30FP          1          3      0.817          1      0.995       0.73\n",
      "                  35FP          1          3      0.804          1      0.995      0.764\n",
      "            38BRKR_ATT          1          2       0.55          1      0.995      0.895\n",
      "                  40FP          1          4      0.317       0.75      0.518      0.405\n",
      "                  45FP          1          3      0.552          1       0.83      0.748\n",
      "                50FPUP          1          1          1          0      0.497      0.398\n",
      "                 Arrow          1          1          1          0      0.995      0.597\n",
      "              AUTOXFMR          1          1      0.454          1      0.995      0.895\n",
      "              BRKR_ATT          1          1          1          0      0.142     0.0995\n",
      "                   CAP          1          1          1          0      0.166      0.149\n",
      "                 CKTSW          1          1          1          0      0.995      0.599\n",
      "                    CT          1          1      0.591          1      0.995      0.597\n",
      "                CTASSY          1          1      0.551          1      0.995      0.895\n",
      "                   DDE          1          1      0.558          1      0.995      0.895\n",
      "               DIPPOLE          1          1       0.76          1      0.995      0.895\n",
      "                 FRGNP          1          4      0.679          1      0.995      0.852\n",
      "                FUCLSP          1          1          1          0     0.0452     0.0407\n",
      "               FUCOMGO          1          1     0.0504      0.101      0.497      0.398\n",
      "                   GEN          1          3      0.532      0.667      0.641       0.56\n",
      "                  GEN1          1          1      0.453          1      0.497      0.448\n",
      "                 GNDSW          1          1          1          0      0.142      0.128\n",
      "                  GOBS          1          1      0.327          1      0.995      0.796\n",
      "                JUMPER          1          1          1          0      0.249      0.174\n",
      "                   LDE          1          1      0.299      0.598      0.497      0.398\n",
      "               LTERMLB          1          1          1          0      0.332      0.298\n",
      "              LTERMNLB          1          1          1          0      0.332      0.232\n",
      "                  MOCS          1          1          1          0      0.332      0.171\n",
      "                PTXFMR          1          1          1          0     0.0311     0.0249\n",
      "                   REG          1          1          1          0      0.995      0.597\n",
      "                   SBD          1          1          1          0      0.497      0.348\n",
      "                   SEC          1          1          1          0     0.0433     0.0303\n",
      "                   SPD          1          1          1          0      0.166     0.0995\n",
      "              STA_SERV          1          1      0.619          1      0.995      0.995\n",
      "               SWFUCOM          1          1          1          0      0.332      0.298\n",
      "                  TPGO          1          1          1          0      0.332      0.265\n",
      "              WAVETRAP          1          1      0.662          1      0.995      0.796\n",
      "        WAVETRAP_NOPOT          1          1      0.403          1      0.995      0.995\n",
      "          WAVETRAP_POT          1          1      0.406          1      0.995      0.895\n",
      "                  XFMR          1          1      0.594          1      0.995      0.796\n",
      "Speed: 4.2ms preprocess, 251.9ms inference, 0.0ms loss, 125.5ms postprocess per image\n",
      "Results saved to \u001b[1m/Users/enerinn/Developer/CS25-338-main/runs/detect/train132\u001b[0m\n",
      "0.5231079313154257\n",
      "\n",
      "image 1/1 /Users/enerinn/Developer/CS25-338-main/Model/images/train/Screenshot 2024-10-09 215306.png: 640x640 1 SEC, 22.2ms\n",
      "Speed: 40.6ms preprocess, 22.2ms inference, 764.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'show'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(metrics\u001b[38;5;241m.\u001b[39mbox\u001b[38;5;241m.\u001b[39mmap)  \u001b[38;5;66;03m# Check mAP score\u001b[39;00m\n\u001b[1;32m     12\u001b[0m results \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimages/train/Screenshot 2024-10-09 215306.png\u001b[39m\u001b[38;5;124m\"\u001b[39m, conf\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m)  \u001b[38;5;66;03m# Inference on a single image\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m \u001b[43mresults\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'show'"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a pre-trained YOLO model\n",
    "model = YOLO(\"yolo11n.pt\")  # Use 'yolov8s', 'yolov8m', etc., for larger models\n",
    "\n",
    "# Train the model\n",
    "results = model.train(data=\"./data.yaml\", epochs=5, device=\"mps\")\n",
    "\n",
    "\n",
    "metrics = model.val()\n",
    "print(metrics.box.map)  # Check mAP score\n",
    "results = model(\"images/train/Screenshot 2024-10-09 215306.png\", conf=0.1)  # Inference on a single image\n",
    "results.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
